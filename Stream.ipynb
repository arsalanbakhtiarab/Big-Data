{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab7061ba-d281-456a-9a7b-ce539bced3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309ad7db-de8b-4347-8df3-c13a460a27b8",
   "metadata": {},
   "source": [
    "### Creating Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a04e4838-4250-444d-ae1b-f9a57e96ef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Stram\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf432d-0207-4554-abeb-3af6b024d0ac",
   "metadata": {},
   "source": [
    "### Define the Input source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7066ff0b-8093-4174-bd4c-f0a927dce34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = (spark.readStream.format(\"socket\").option(\"host\",\"localhost\").option(\"port\",9999).load())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b42f0-a1dc-4da6-b239-49afc5c276d5",
   "metadata": {},
   "source": [
    "### State less transformation and state full transformaiton\n",
    "- State less i.e select operation filter map this do not required any transformatin from previos rows for processing the next row so each row can be process by it self. it can be apply on both the batch and streaming.\n",
    "- State full transformation i.e The aggregation operation like count will required mentaning the state of the combine data accross the multiple rows. grouping and joins are included. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85016c8f-6d7c-476e-8773-efe5052d920c",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab58f99-9ccb-4c33-b799-779d6e067f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = lines.select(split(col(\"value\"),\"\\\\s\").alias(\"word\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6a7784-7fe9-4a0a-814d-2819edb276c1",
   "metadata": {},
   "source": [
    "### Get the count of published words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ebeffc-ddc9-4c15-8171-05df5fd8ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = words.groupBy(\"word\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017160ef-7436-4182-99bb-597518740c97",
   "metadata": {},
   "source": [
    "### Checkpoint Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bba6eb62-2226-426b-a5d7-3ca85b91fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointDir = \"D:/checkpoint/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66285f27-e7a9-447e-88d5-37bc21e0a7d2",
   "metadata": {},
   "source": [
    "### Start Streaming defining the necessary configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0462568-e353-48e2-a641-d276478306ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamingQuery = (counts\n",
    "                  .writeStream.format(\"console\")\n",
    "                  .outputMode(\"complete\")\n",
    "                  .trigger(processingTime=\"0.4 second\")\n",
    "                  .option(\"checkpointLocation\",checkpointDir)\n",
    "                  .start()\n",
    "                 )\n",
    "streamingQuery.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92a891-16a8-4a44-b7df-a2eb22fe8ec1",
   "metadata": {},
   "source": [
    "### To run the socket connection of nmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ba7b5-39e3-4e8a-90ef-a765bd313832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ncat -l 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a46fe-9292-4e2b-93f0-6deca81e82af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines = (spark.readStream.format(\"socket\").option(\"host\",\"localhost\").option(\"port\",9999).load())\n",
    "words = lines.select(split(col(\"value\"),\"\\\\s\").alias(\"word\"))\n",
    "counts = words.groupBy(\"word\").count()\n",
    "checkpointDir = \"C:/checkpoint/\"\n",
    "streamingQuery = (counts\n",
    "                  .writeStream.format(\"console\")\n",
    "                  .outputMode(\"complete\")\n",
    "                  .trigger(processingTime=\"0.4 second\")\n",
    "                  .option(\"checkpointLocation\",checkpointDir)\n",
    "                  .start()\n",
    "                 )\n",
    "streamingQuery.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dcc292-8279-4a51-b8d3-d53d43d0c343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a89e4f-ba9d-4c0a-ab53-8c670ccadc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
